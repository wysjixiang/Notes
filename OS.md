# 操作系统学习笔记、



### 1.导论

1. SMP：对称多处理器 Symmetric MultiProcessor. 所有处理器共享内部物理资源，如总线、内存等

2. 高速缓存一致性，通常是硬件来处理的！

3. Linux内核所用的数据结构有源码可学习：

   <linux/list.h>链表数据结构；

   kfifo.c包含队列实现，linux的队列称为kfifo；

   <linux/rbtree>通过红黑树提供平衡二分查找树的实现

4. 嵌入式系统几乎总是采用实时操作系统，当处理器执行或数据流动具有严格的时间要求时，不二之选
5. GNU通用公共许可证 GNU General Public License, GPL，是著佐权的条文



### 2. 操作系统结构

1. 用户与操作系统的界面有多种方式，其中一种就是提供命令行界面或命令解释程序，允许用户直接输入命令以供操作系统执行。例如shell，就是一个解释程序。在类UNIX系统下，命令解释程序不需要理解指令，而只要通过命令确定一个文件，以加载到内存并执行。例如 rm fuke txt这个命令，会查找名为rm的文件，并用后续参数执行！
2. 系统调用提供操作系统服务接口，在编译时，由编译器直接提供函数库来提供系统调用接口，以链接到操作系统的系统调用
3. 系统调用大致可分为6大类：进程控制、文件管理、设备管理、信息维护、通信和保护
4. 进程间通信的常用模型哟有两个：消息传递模型和共享内存模型
5. 后台服务： 所有通用系统都由方法，以便在引导时创建一些系统程序的进程。这些进程中有的执行完任务后就终止，有的会一直运行到系统停机。一直运行的系统进程，成为服务、子系统或者守护进程。比如一个监听网络连接请求的服务。
6. 加载内核以启动计算机的过程，称为引导。当CPU收到一个重置事件时，例如上电开机或重启，指令寄存器就会加载某个预先定义的内存位置，并从该位置开始执行，该位置就是初始引导程序所在。该程序为只读存储器形式，因为系统启动时RAM处于未知状态。
7. 引导程序可以完成一系列任务，如初始状态诊断、初始化系统等，最终他会启动操作系统。一般引导程序存放再固件上，如EEPROM，而操作系统存放在磁盘、固态等上，在启动时，引导程序会把操作系统先搬运到RAM中再运行

 

### 3. 进程

1. #### 什么时进程？结合线程来说明他们的概念，相同点，不同点。。。！！ 

2. 进程本身也可以作为一个环境，用于执行其他代码，典型的就是JAVA编程环境

3. 操作系统内的每个进程表示，可以采用进程控制快(Process Control Block, PCB)来表示，也称为任务控制快

4. 大多数操作系统对进程的识别采用的是唯一的进程标识符（process identifier，pid），通常是一个整数值

5. 进程init的pid总是1,作为所有用户进程的根进程或父进程

6. 如果一个进程终止，那么它的所有子进程也终止，这种现象，称为级联终止

7. 僵尸进程：当一个进程终止时，操作系统会释放资源，但是他位于进程表中的条目还是在的，直到他的父进程调用wait()。当进程终止但是父进程尚未调用wait，这样的进程就是僵尸进程

8. 如果父进程没有调用wait()就终止，子进程就成了孤儿进程。在linux中，就会将init进程作为孤儿进程的父进程，init会定期调用wait

9. 进程之间可以是独立的也可以是协作的。如果一个进程不影响其他进程或受其他进程影响，那么他就是独立的，否则就是协作的

10. 进程间通信，IPC（InterProcess Communication）

11. #### 共享内存系统

    1. 进程间通信有两种模型，一个是共享内存，另一个是消息传递。消息传递一般通过系统调用来实现
    2. 在共享内存模型中，数据的类型或位置不受操作系统控制，而是由进程决定，另外进程需要确保他们不会向同一个位置同时写入数据
    3. 生产者—消费者问题，这是协作进程的通用范例。生产者进程生成信息，以供消费者进程消费。为了两者并发执行，应有一个可用的缓冲区，生产者和消费者必须同步，避免消费未生产出来的数据
    4. 缓冲区类型可以分为无界缓冲区和有界缓冲区。无界缓冲区生产者可以一直产生新项，而消费者可能需要等待；而对于有界而言，可能两者都需要等待

12. #### 消息传递系统

    1. 直接通信的缺点就是更改进程表示符后需要修改其他所有进程的相关通信定义，所有旧标识符都要被找到并修改为新的
    2. 间接通信解决这一问题，采用邮箱或端口来发送和接受消息。只有两个进程共享一个邮箱时，才能建立通信链路
    3. 阻塞、非阻塞，即同步、异步问题。

13. #### 管道

    1. 管道允许两个进程进程通信，是早期UNIX系统最早使用的一种IPC机制
    2. 普通管道允许两个进程按标准的生产者—消费者方式进行通信，普通管道是单向的，只允许单向通信。如果需要双向，就要使用两个管道

14. #### 长期调度、中期调度和短期调度

    1. 长期调度（Long-term Scheduling）：
       - 功能：长期调度也被称为作业调度。它是在作业进入系统时进行的调度过程，决定是否将作业从作业队列中调入内存中执行。
       - 调度对象：调度的对象是作业（Job）或进程（Process）。
       - 目标：其目标是控制系统中的作业数量，以保持系统的吞吐量和资源利用率。
    2. 中期调度（Medium-term Scheduling）：
       - 功能：中期调度也被称为内存调度或交换调度。它是在内存中运行的进程过多时，将一部分进程从内存中调出，暂时存放到磁盘上，以提高系统的性能和吞吐量。
       - 调度对象：调度的对象是进程。
       - 目标：其目标是控制内存中的进程数量，以避免过度调度和资源竞争，提高系统的响应时间和吞吐量。
    3. 短期调度（Short-term Scheduling）：
       - 功能：短期调度也被称为CPU调度或进程调度。它是在内存中已经就绪的进程之间进行的调度过程，决定哪个进程将获得CPU的使用权。
       - 调度对象：调度的对象是进程。
       - 目标：其目标是提供公平的CPU时间分配，最大限度地减少等待时间，提高系统的响应速度和吞吐量。

### 4. 多线程编程

1. 线程是资源共享的，多个线程默认共享他们所属进程的内存和资源
2. 异步线程和同步线程。对于异步线程，一旦父线程创建了子线程后，父线程就恢复自身的执行，这样父线程会和自线程并发执行。而同步线程是父线程创建一个或多个子线程之后，子线程并发执行，但是父线程在子线程没有完成工作之前无法继续，会阻塞。只有所有子线程终止并于父线程连接之后，父线程恢复执行。通常同步线程涉及线程之间大量数据的共享。
3. 线程池： 线程池的思想是：在进程开始时创建一定数量的线程，并加到池中以等待工作。当服务器收到请求时，他会唤醒池内的一个可用线程，并将需要服务的请求传递给他。一旦线程完成了服务，他会返回到线程池中再等待工作唤醒。如果线程池中没有可用线程，那么服务器会等待，直到有可用线程为止
4. 传递信号的标准UNIX函数为kill(pid_t pid, int signal)，这个函数将一个特定信号传递到一个进程
5. 线程撤销：是在线程完成之前终止线程
6. Linux通过系统调用fork()提供进程赋值的功能，通过系统调用clone()提供创建线程的功能，但是Linux并不区分进程和线程，在讨论程序的控制流时，通常采用任务task一词来描述
7. 线程是进程内的控制流，是进程的一部分。线程间共享内存和其他资源



### 5. 进程调度

1. 非抢占(协作)调度和抢占调度：非抢占调度下，一旦某个进程分配到CPU，该进程就会一直使用CPU，直到他终止或切换到等待状态。

2. 调度程序是一个模块，用来将CPU控制交给由短期调度程序选择的进程。调度程序应尽可能快。调度程序停止一个进程而启动另一个进程的所需时间称为调度延迟

3. 轮转Round-Robin调度算法是专门为分时系统设计的

4. 多级队列调度：将就绪队列分成多个单独队列，根据进程属性，如优先级、进程类型等，分配不同队列，每个队列对应不同的调度算法。而不同队列之间也有调度，通常采用固定优先级抢占调度

5. 线程调度中一个重要概念：在支持线程的操作系统上，内核级线程（而不是进程）才是操作系统所调度的。用户级线程是由线程库来管理的，而内核并不知道他们。用户级线程为了运行在CPU上，最终应映射到相关的内核级线程，但是这种映射不是直接的，可能采用轻量级进程（LWP）。

6. 处理器核的多线程：粗粒度和细粒度的多线程。对于粗粒度的多线程，线程一直在处理器上执行，直到一个长延迟事件，如内存停顿发生。细粒度的多线程在更细的粒度上切换线程，比如在指令周期的边界上，这时候切换进程后冲刷CPU流水线带来的切换成本很小。

7. #### Linux内核中的线程调度算法：

   Linux内核中的线程调度算法主要是基于完全公平调度（CFS，Completely Fair Scheduler）。CFS是Linux 2.6内核引入的一种红黑树调度算法，旨在提供公平的CPU时间分配和高性能的多任务处理。

   CFS的主要特点和算法原理如下：

   1. 时间片分配：CFS不采用传统的固定时间片轮转调度算法，而是使用红黑树数据结构来维护任务队列。每个任务（进程或线程）都有一个虚拟运行时间（vruntime）来衡量其执行时间。任务的vruntime值越小，表示它已经消耗了更多的CPU时间，优先级较高。
   2. 公平性：CFS追求完全公平调度，即每个任务在一段时间内都能获得相同的CPU时间比例。通过计算任务的vruntime和实际消耗的CPU时间之间的差值，调度器决定下一个执行的任务。
   3. 动态优先级：CFS使用动态优先级来决定下一个要执行的任务。通过计算任务vruntime与系统当前时间的差值，可以确定任务的优先级。vruntime越小的任务，优先级越高。
   4. 实时任务支持：CFS还支持实时任务调度。实时任务通常具有较高的优先级和严格的时间限制。CFS通过与普通任务分开的红黑树来管理实时任务队列，并使用优先级划分来确保实时任务能够及时响应。

   CFS的设计目标是提供公平、高性能和低延迟的调度。它能够根据系统负载和任务需求进行动态调整，以适应不同的工作负载和系统环境。除了CFS，Linux内核中还有其他调度算法，如实时调度器（SCHED_FIFO、SCHED_RR）和实时公平调度器（SCHED_DEADLINE），用于特定的调度需求和场景。



### 6. 同步

1. 临界区问题，互斥的解决，硬件的原子指令

2. 抢占式内核与非抢占式内核

3. #### 互斥锁

   1. 自旋锁: spinlock,将一直循环等待临界区的锁被释放，适用于对临界区数据处理较快的情况，这样不会造成CPU的浪费
   1. 信号量、mutex互斥锁都可以认为是互斥锁
   1. 自适应互斥锁：主要针对多处理器系统，如果数据已经被加锁，而此时持有锁的线程正在其他cpu上运行，那么表示持有锁的线程可能很快就会结束，因此此时会采用自旋的方式等待；而如果此时持有锁的线程未处于运行状态，则进入睡眠以避免自旋。因此对于但处理器系统来说，自适应互斥锁没能获得锁的情况下总是睡眠
   1. 读写锁：这是读者—作者问题的一种解决方案。对于经常访问但是通常只读访问的数据保护，通常使用读写锁。
   1. 

4. #### 信号量semaphore

   1. 除了初始化外只能使用两个原子操作指令，wait()和signal()会包含这两个原子指令，分别是立增和立减
   2. 信号量分为二值信号量和计数信号量。计数信号量类似与RTT中的sema，而二进制信号量就类似mutex
   3. 如果执行wait()之后无法得到信号量，则会阻塞自己，把自己放到与信号量相关的等待队列中，并且将该进程的状态切换为等待状态，等到signal()被执行后通过wakeup()再唤醒这个进程。与RTT中的处理是一样的
   4. 
   5. 

5. 需要指出的一点是，在但处理器中，可以简单使用关中断的方法来实现互斥操作，就像在RTT中实现的那样，在mq,mailbox,mutex,sema等操作中，首先的处理步骤就是关中断，然后在来处理互斥量，之后再开中断

6. #### 死锁

   1. 多个进程无限等待一个事件，而这个事件又只能由等待的进程来实现，这样的状态就成为死锁
   2. 优先级反转问题，高优先级进程等待低优先级释放锁。

7. #### 经典同步问题

   1. 有界缓冲问题： 即资源数不是二值的，而是多个，类似RTT中的sema和mailbox
   2. 读者-作者问题：即对于临界区数据的只读模式，可以支持多个进程并发访问，这可以认为是读者模式；而对于作者来说，当他在写时，不应该有其他进程访问临界区。因此我们可以同时维护两把锁，一把锁分配给读者，他们可以同时并发访问，而另一把分配给作者，他必须是互斥的
   3. 哲学家就餐问题：是描述多个进程访问多个资源的典型例子。操作系统应该确保在处理这类模型时候，不会让进程出现死锁或者饥饿的状态。死锁的问题有很多补救措施，比如要求哲学家只有同时能获取到两只筷子时才能拿起筷子，或者单号拿左边的筷子等。但是在解决方案上，有可能解决死锁的方案并不一定能保证进程不会出现饥饿。

8. linux内核是可抢占内核
9. linux内核中最简单同步技术为原子整数，它的数据类型为抽象数据类型atomic_t。所有相关的数学运算在执行时不会中断。
10. Linux提供互斥锁，用于保护内核中的临界区。调用mutex_lock()加锁，mutex_unlock()解锁。如果锁不可用，则会睡眠，当锁被释放后会被唤醒
11. 对于多处理器来说，基本加锁机制为自旋锁，内核设计成只有段时间的操作，彩绘采用自旋锁。对于仅有单个处理核的嵌入式系统，自旋锁不适用，而替换成内核抢占的启用与禁用。
12. linux通过两个简单的系统调用preempt_enable()和preempt_disable()来启用和禁用内核抢占。然而如果内核态的一个任务占有锁，那么内核是不能被抢占的。内核中会有相关数据结构来保证这一点
13. Pthreads API只能被用于用户级别的程序员使用，而不能用于内核中。这个API为线程同步提供互斥锁、条件变量和读写锁。
14. 命名信号量与无名信号量。命名信号量在文件系统中有实际名称，并且能被多个不相关进程所共享。无名信号量只能被同一进程的线程所使用，
15. 事务内存:它是一个内存读写操作的序列，是原子的。如果事务中的所有操作都完成了，内存事务就被提交，否则，终止操作并且回滚。没有锁的机制，事务性内存系统而非开发人员负责保证原子性。可以通过软件实现，也可以通过硬件实现—硬件实现需要修改缓存层次结构和缓存一致性协议才能支持事务内存



### 7. 死锁

1. 死锁的必要条件：如果一个系统中以下4个条件同时成立，那么就能引起死锁

   1. 互斥：至少有一个资源必须处于非共享模式。
   2. 占有并等待：一个进程应占有至少一个资源，并等待另一个资源，而该资源被其他进程所占有
   3. 非抢占：资源不能被抢占
   4. 循环等待：有一组等待进程{p1,p2,....,pn},p1等待的资源被p2所占有，p2等待的资源被p3所占有......

2. 强调所有四个条件必须同时成立才可能会出现死锁(为什么不是必定呢？因为这和CPU调度相关。并不是每一次运行都会出现死锁，而考虑无穷次的情况下，则必定会出现死锁情况！因而死锁也是很难检测并解决的)

3. #### 死锁的处理方法：

   1. 通过协议来预防或者避免
   2. 可以允许操作系统进入死锁状态，然后检测他并加以恢复
   3. 可以忽视这个问题，认为死锁不可能在系统内发生

4. 处理方法中大多数操作系统都假定不会发生死锁，包括windows和linux。因此这个问题要由程序员来解决。至于为什么操作系统大多忽视死锁，则是由处理死锁所带来的频繁且昂贵的开销和死锁发生的可能性来考虑的。

5. #### 死锁预防

   只要破坏发生死锁的4个必要条件即可实现死锁预防。主要是通过限制如何申请资源来预防，这样带来的副作用也很明显，设备的使用率和系统吞吐率都很低

   1. 互斥条件破坏：比如对于只读文件来说，没有必要给他加锁，因此也就不会产生互斥
   2. 持有且等待破坏：可以采用一种协议的方法，当一个进程申请一个资源的时候，他本身此时不能占有资源，即只有没由占有资源的进程可以申请资源。而还可以有另一种协议方法：每个进程在执行前申请并获得所有资源（没有获得所有资源之前不会运行进程），并且在整个执行过程中会一直占有资源。这两种协议方法都有很大的缺点：1是资源利用率很低，许多资源被分配但是很长时间没有使用。2是可能发生饥饿，一个进程如果需要多个常用资源，可能需要永久等待，因为他所需要的资源中至少有一个已经分配给其他进程了
   3. 无抢占破坏：采用如下协议：当一个进程持有资源并且申请另一个不能立即分配的资源的时候，他所持有的资源变为可抢占。这个协议仅适用于CPU寄存器和内存，其他如互斥锁、信号量等资源都不适用！
   4. 循环等待破坏：可以采用如下方法：对所有资源类型进行完全排序，而且要求每个进程按递增顺序来申请资源。假设资源类集合R = {R1,R2,R3.....Rm},为每个资源类分配一个唯一整数，这样就有一个映射F： R —> N。一开始进程可以申请任意资源，之后，当且仅当F(Ri) > F(Rj)的时候，才可以申请Rj资源的实例。否则就要先释放资源，再去申请！这样就可以保证不会发生循环等待.

6. 死锁避免：也是一个需求很复杂的算法。主要就是操作系统提前获悉每个进程可能需要的每种类型的资源的数量、种类、顺序等，动态检查各个进程的资源占有状态来分配资源

7. 死锁恢复：一个选择是简单地中止一个或多个进程来打破循环等待，另一个是从一个或多个死锁进程那里抢占一个或多个资源



### 8.  内存管理

1. #### 地址绑定

   1. 绝对代码地址在编译时确定
   2. 可重定位代码地址在加载时确定
   3. 使用虚拟地址的话，则实际的物理地址会在执行时动态确定，这个需要硬件MMU(Memory-Management Unit)支持
   4. CPU生成的地址通常称为逻辑地址，也可以被称为虚拟地址，而内存单元看到的地址通常称为物理地址

2. 动态加载：一个程序只有在调用时才会加载

3. #### 动态链接与共享库

   1. 动态链接为系统库，可链接到用户程序，以便运行。有的操作系统只支持静态链接，他的系统库与其他目标文件一样，通过加载程序被合并到二进制程序映像中。而动态链接类似于动态加载，但这里不是加载，而是链接，会延迟到运行时。
   2. 如果有动态链接，在二进制映像内，每个库程序的引用都有一个存根。存根是一小段代码，用来指出如何定位适当的内存驻留库程序，或者在程序不在内存时应如何加载库。
   3. 动态链接也可以用于库的更新，如修复bug等。这样不同版本的动态程序可以形成多版本的系统，这种系统也称为共享库。
   4. 动态链接通常需要操作系统的帮助！只有操作系统才可以检查所需程序是否在某个进程的内存空间内，或是允许多个进程访问同样的内存地址

4. #### 交换

   1. 进程可以暂时从内存交换到备份存储中，当再次执行时再调回到内存中。交换有可能让所有进程的总的物理地址空间超过真实系统的物理地址空间

   2. ##### 标准交换

      1. 标准交换再内存于备份存储之间移动进程。备份存储通常是快速磁盘。系统维护一个可运行的所有进程的就绪队列，他们的映像在备份存储或者内存中。当CPU调度器决定要执行一个进程时，他调用分派器，检查队列中下一个进程是否在内存中。如果不再，并且没有空闲内存区域，那么分派器会还出当前位于内存的一个进程，并换入所需进程，然后重新加载寄存器！！并且CPU分配给该进程。
      2. 交换时间主要取决于交换进程所占内存的大小、数据传输效率
      3. 这种交换系统的上下文切换时间相当高！！而且在换出程序上还有许多考量，比如换出程序是否在等待I/O等
      4. 现代操作系统并不使用标准交换，因为交换时间太多，执行时间太少，不是合理的内存管理解决方案。
      5. 但是这种交换的变种却在许多操作系统中得到应用，比如UNIX、Linux、WIndows。
      6. 一个常用的变种是，正常情况下禁止交换；当空闲内存(未被操作系统或进程使用的内存)低于某个阈值时，启用交换。当空闲内存的数量增加了，就停止交换。
      7. 另一个变种是交换进程的部分，而不是整个进程，以降低交换时间

   3. 移动系统的交换。移动系统通常不支持任何形式的交换，主要原因是存储空间限制。当空闲内存降低到一定阈值以下时，IOS系统不采用交换，而是要求应用程序自愿放弃分配的内存。只读数据如代码可从系统中删除，已修改的数据如堆栈不会删除，但操作系统可以终止任何未能时方足够内存的应用程序

   4. 

5. #### 连续内存分配

   1. 多分区方法：将内存划分为多个固定大小的分区，每个分区可以只包含一个进程。因此多道程序的程度受限于分区数。现代操作系统不使用这种方法
   2. 可变分区方案：操作系统维护一个表，记录已用内存和可用内存，并根据内存的使用情况和调度算法来分配内存给进程
   3. 内存碎片可以是内部的，也可以是外部的
      1. 内部碎片：当一个进程需要的空间不是N字节对齐的，比如我需求4095个字节，但是我分配的时候会按照对齐方式分配，给他分配4K个字节的空间，因此会多处1个字节的碎片，这个碎片处于进程内部，并且进程不会使用他
      2. 外部碎片：空闲内存空间被分为了很多个小的片段，当总的可用内存之和可以满足内存分配请求，但他们又不连续时，就出现了外部碎片问题
   4. 外部碎片的问题。可以通过分页或者分段的方法来解决。因为对于这两种方法，他们支持虚拟地址连续而物理地址不连续！

6. 分段：段表：段表的每个条目都有段基地址和段界限。段基地只包含该段在内存中的开始物理地址，段界限指定该段的长度。这一点非常类似于PA中的ramdisk的组织方式！！

7. 紧缩：紧缩就是在内存中移动程序，且不影响程序的运行。是外部碎片问题的解决方法之一

8. #### 分页

   1. 分页与分段相比更有优势。分页避免了外部碎片和紧缩；同时分页也避免了将不同大小的内存块匹配到交换空间的麻烦问题

   2. 分页机制为目前大多数操作系统所采用，分页机制的实现需要操作系统和计算机硬件的支持，尤其是MMU硬件

   3. 具体实现你应该已经相当清楚了，尤其是对于RV64指令集，你实现了sv39分页机制，该分页机制包含3层页表，虚拟地址的低12位（11-0）作为页偏移值，而38-12位，分为3段，每一段作为一层页表的索引。因为是4K字节对齐的分页，而9bit可以表示0-1023共1024个值，恰好RV64是64位的，一个地址数据占4位，因此这些值就是页表项的索引，即1024个索引，可以遍历1层页表项。而页表项存储的内容就是下一层页表的地址！（忘了就回去看看原来写的nanos代码）

   4. 当然不同的操作系统，他们的分页机制不同，因此不一定是4K页对齐，但是RV64肯定是4K对齐

   5. Linux系统上页大小根据架构而变化

   6. 采用分页机制不会产生外部碎片，这是显而易见的，因为虚拟地址是按页分配的，1页虚拟地址正好对应1页物理地址，所以不存在外部碎片，但会有内部碎片

   7. 分页机制一个重要方面就是程序员视角的内存和实际物理内存的解耦分离！这样给我们操作系统运行多个被编译为绝对代码地址的程序带来便利。另外一个用户程序也只能访问他所被分配到的页的物理地址，这样就可以检测他是否访问了非法的地址

   8. 上下文切换的时候增加了点开销，Satp寄存器！

   9. 分页表是由操作系统维护的，用户进程完全无需考虑相关的事项

   10. #### 硬件支持！

       1. 每个进程独有的页表头指针，需要被保存到进程控制块中。同时会有硬件寄存器（Satp寄存器）来装载这个值
       2. 另外虚拟地址转换为物理地址，也是需要加速的，否则会严重影响CPU的执行速度。这一点其实和高速缓存cache很类似，需要硬件加速支持。
       3. 转换表缓冲区(Translation Look-aside Buffer, TLB)就是干这个活的。TLB是关联的高速内存。TLB条目由两部分组成：键(标签)和值。大致原理和cache命中是一样的。硬件CPU会首先在TLB上面查找，看看虚拟地址是否命中，如果命中，他的物理地址就可以立刻得到，可以马上进行访存操作；如果未命中，那么才需要区访问页表。
       4. 现代TLB查找硬件是指令流水线的一部分，基本不添加任何性能负担
       5. TLB中条目数量是有限制的，因此管理条目也是有一定算法的。如果TLB条目已经满了，那么就需要替换一个条目。替换策略很多，如轮转替换、随即替换等，当然最常用的就是LRU—最近最少使用替换
       6. 另外有一些条目在TLB中固定下来之后允许不被替换，通常是一些重要内核代码的
       7. 有的TLB还额外支持ASID（Address-Space Identifier，ASID）地址空间标识符。ASID唯一标识每个进程，并为进程提供地址空间的保护。因此当ASID不匹配时，也会被认为未命中。如果TLB不支持单独的ASID，每次选择一个页表的时候，即上下文切换的时候，TLB必须要被刷新！！以确保下一个进程不会使用错误的地址转换

   11. 页保护：这个很容易实现。如Sv39虚拟内存布局。在3层页表中的低10位（9-0bit）都是用来描述页表项状态的，如只读、只写、页无效、页有效等等！

   12. 共享页：分页的优点之一就是可以共享公共代码。可重入代码(Reentry code)也叫[纯代码](https://baike.baidu.com/item/纯代码/5669644?fromModule=lemma_inlink)(Pure code)是一种允许多个进程同时访问的代码。为了使各进程所执行的代码完全相同，故不允许任何进程对其进行修改。[程序](https://baike.baidu.com/item/程序/71525?fromModule=lemma_inlink)在运行过程中可以被打断，并由开始处再次执行，并且在合理的范围内（多次重入，而不造成[堆栈溢出](https://baike.baidu.com/item/堆栈溢出/1231765?fromModule=lemma_inlink)等其他问题），程序可以在被打断处继续执行，且执行结果不受影响。对于可重入代码，无疑多个进程可以共享这段代码所在的页

   13. #### 页表结构

       1. 分层分页：这个应该很熟悉了，如Sv39就是3级分层页表

       2. ## **<u>哈希页表：得先学习下什么是哈希。。。</u>**

       3. 倒置页表




### 9. 虚拟内存管理

1. 虚拟内存技术允许执行进程不必完全处于内存，程序可以大于物理内存

2. 虚拟内存允许文件和内存通过共享页而为多个进程所共享。系统库就是如此，通常库按只读方式映射到与其链接的进程空间

3. 类似地，虚拟内存允许共享内存

4. #### 请求调页

   1. 程序执行之前，操作系统并没有把程序代码全部加载到内存中，而是仅在需要的时候才加载页面，这种技术叫做请求调页，常常用于虚拟内存
   2. 当进程访问那些还没有被调入内存的内面时，会发生缺页错误，触发异常陷入操作系统，再去调入需要的页
   3. 当然，如果只在需要时才去调用页，效率会低得难以接受，因此操作系统有更多的方案来优化，如局部引用
   4. 对于请求调页来说，降低缺页错误率是极为重要的！因为将外部磁盘的数据读入内存中极为耗时，会极大增加有效访问时间，减缓进程执行速度

5. 写时复制：这种技术可以在创建新进程的时候绕过请求调页需求，提供快速的进程创建，并最小化必须分配给新创建进程的新页面的数量。通过系统调用fork()的进程创建最初可以通过类似页面共享的技术，来绕过请求调页。系统调用fork()为子进程创建一个父进程的一个复制，以作为子进程。传统上，fork()为子进程创建一个父进程地址空间的副本，复制属于父进程的页面。然而考虑到许多子进程在创建之后会立马调用系统调用exce() ，父进程地址空间的复制可能没有必要，因此采用一种写时复制的技术。它允许父进程和子进程共享相同的页面来工作，这些共享页面会被标记为写时复制，即只有父进程或子进程要对共享页面中的内容做修改时，子进程才会创建共享页面的副本，与父进程对该页分离不共享。一开始的时候其实子进程共享了父进程的堆栈！

6. UNIX的多个版本包括linux提供了fork()的变种，vfork()，虚拟内存fork。他不同于写时复制，采用Vfork，父进程被挂起，子进程使用父进程的地址空间。如果子进程修改父进程地址空间的任何页面，那么这些修改过的页面对于恢复的父进程是可见的！

7. #### 页面置换：

   1. ##### 基本页面置换规则：

      1. 当申请一个页面而没有空闲帧时，操作系统查找目前不在使用的一个帧，将他的内容写到交换空间，并释放它以分配给申请者。释放的过程就是修改所有相关页表来表示该页目前不在内存中。
      2. 在硬件上可以采用修改位来标识。即如果要置换的这个帧从磁盘取出后没有被修改过，那么就表示他的内容和磁盘里的内容是一样的，因此不需要将他的内容重新写回磁盘，而可以直接释放然后分配给申请者，这是需要硬件辅助标识修改位的
      3. 需要特定算法支持，如帧分配算法、页面置换算法，才能高效实现页面置换功能，否则效率极为低下

   2. FIFO页面置换

      1. 最简单的页面置换算法。这个不需要过多解释了，性能低下

   3. 最优页面置换：即置换最长时间不会使用的页面！这是对将来可能需要使用的时间而言的，请与LRU算法区分开。这种算法保证对于给定数量的帧会产生最低可能的缺页错误率

   4. LRU页面置换：Least-Recent-Used algorithm，最近最少使用算法。通常使用堆栈的方式来实现查找最少使用页面。

   5. 需要注意，最优页面置换和LRU算法都是需要硬件支持的！如果要依靠软件解决，效率太低不现实。但很少有计算机系统能提供足够的硬件来支持真正的LRU页面置换算法。因此操作系统会使用其他一些算法来做页面置换，如近似LRU算法

8. 内存映射：采用虚拟内存技术，以将文件I/O作为常规内存访问，这种方法就是内存映射。基本机制是：将每个磁盘块映射到一个或者多个内存页面。最初文件访问按照普通请求调页来进行，这样文件的内容就被从文件系统读取到物理内存页面。以后文件的读写就按照常规的内存访问来处理，这样没有read()，write()的开销，而且简化了文件的访问和使用。多个进程可以并发的内存映射同一文件，以便允许数据共享

9. 内存映射I/O：这个你应该很熟悉!比如串口数据怎么发的，你就是往特定地址写数据，这个地址其实就是映射到串口I/O寄存器的！！许多计算机体系结构提供了内存映射I/O，在这种情况下，一组内存地址专门映射到设备寄存器，对这些内存地址的读取和写入，就和对这些设备寄存器读取和写入一样！

10. 虚拟内存能将较大的虚拟地址（逻辑地址）空间映射到较小的物理内存。允许运行极大的进程，提高多道程度（即运行很多进程的能力）；他还可以让程序员不必担心内存可用性；允许多个进程共享系统库和内存。
